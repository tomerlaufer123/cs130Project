{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('youreit': conda)",
   "metadata": {
    "interpreter": {
     "hash": "036400ab147c727a32e1594addfccc86371338bb65175d19c34515eac00cc03e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 3. Improve Hashtags\n",
    "\n",
    "HARRISON dataset provides us with images along with their hashtags. But those provided hashtags are not enough to train a model with. For example, a picture of the beach has only one hashtag `sea`, so the model learns the image is associated with `sea` but not `ocean`, `beach`, or any other similar tags.\n",
    "\n",
    "In this section, we improve groud truth values (i.e. true hashtags) by adding more related hashtags. To get similar hashtags, we use [Gensim](https://radimrehurek.com/gensim/index.html) and a [pre-trained model](https://code.google.com/archive/p/word2vec/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Load a Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load a model\n",
    "model = KeyedVectors.load_word2vec_format('../model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('ocean', 0.7643541097640991),\n",
       " ('seas', 0.6712585687637329),\n",
       " ('oceans', 0.6193016767501831),\n",
       " ('waters', 0.5993286371231079),\n",
       " ('seawaters', 0.5960040092468262),\n",
       " ('Creamsicle_orange', 0.58356773853302),\n",
       " ('coastal_waters', 0.5737729072570801),\n",
       " ('wooden_crate_dumped', 0.5657002329826355),\n",
       " ('oceanic', 0.5628669261932373),\n",
       " ('prairies_deserts', 0.5556836724281311)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Get similar word to \"sea\"\n",
    "model.most_similar(\"sea\")"
   ]
  },
  {
   "source": [
    "## Hashtag Similarities\n",
    "First, we analize similarities of existing hashtags."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Read hashtags\n",
    "with open(\"../model/hashtags.txt\") as f:\n",
    "    hashtags = np.array(f.read().split('\\n'))\n",
    "num_hashtags = len(hashtags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix\n",
    "sim_mat = np.zeros((num_hashtags, num_hashtags))\n",
    "\n",
    "for i in range(num_hashtags):\n",
    "    for j in range(i):\n",
    "        try:\n",
    "            sim_mat[i,j] = model.similarity(hashtags[i],hashtags[j])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tags that are similar to sea: ['air', 'beach', 'boat', 'earth', 'fish', 'ice', 'island', 'lake', 'moon', 'ocean', 'river', 'sand']\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary whose:\n",
    "#   key:    hashtag\n",
    "#   value:  similar hashtags\n",
    "sim_tags = {}\n",
    "for i in range(num_hashtags):\n",
    "    # Get similar tags whose cos similarity is > 0\n",
    "    sim_ls = list(hashtags[np.where(sim_mat[i,:]>0.3)[0]])\n",
    "    sim_tags[hashtags[i]] = sim_ls\n",
    "\n",
    "print(f\"Tags that are similar to sea: {sim_tags['sea']}\")"
   ]
  },
  {
   "source": [
    "## Improve `tag_list.txt` Using the Dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Average # of hashtags added: 12.569138276553106\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "for key in sim_tags:\n",
    "    temp += len(sim_tags[key])\n",
    "avg_increase = temp/num_hashtags\n",
    "print(f\" Average # of hashtags added: {avg_increase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# If you restarted kernel, uncomment lines below\n",
    "# with open(\"../model/1113114209_sim_tags.pickle\", \"rb\") as f:\n",
    "#     sim_tags = pickle.load(f)\n",
    "\n",
    "with open(\"../HARRISON/tag_list.txt\") as f:\n",
    "    # Read tag_list\n",
    "    tag_list = f.read().split('\\n')\n",
    "\n",
    "tag_list = np.array([x.split(' ')[:-1] for x in tag_list[:-1]])\n",
    "num_images = len(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_tags(old: list) -> list:\n",
    "    ret = old.copy()\n",
    "    for tag in old:\n",
    "        ret += sim_tags[tag]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_tag_list = [' '.join(expand_tags(x)) for x in tag_list]"
   ]
  },
  {
   "source": [
    "## Save Objects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from utils import destination\n",
    "\n",
    "Save this dictionary to disk\n",
    "with open(destination(\"../model\", \"sim_tags.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(sim_tags, f)\n",
    "\n",
    "# Save new tag_list.txt\n",
    "with open(destination(\"../HARRISON\", \"tag_list.txt\"), \"w\") as f:\n",
    "    f.writelines(\"%s\\n\" % tags for tags in new_tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}